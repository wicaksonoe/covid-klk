{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import library yang diperlukan\n",
    "csv untuk membuat file csv nantinya\n",
    "time untuk menggunakan fungsi time.sleep (suspend fungsi sebentar)\n",
    "os.path untuk pengecekan file di akhir\n",
    "datetime untuk menggunakan fungsi pengambilan tanggal dan waktu scrapping\n",
    "selenium digunakan sebagai virtual browser, karena webpage tidak bisa hanya menggunakan library request,\n",
    "    karena ada data yang lebih mudah diambil, tetapi berada di dalam javascript, jadi perlu eksekusi javascript\n",
    "beautifulSoap adalah library web scrapping python yang di\n",
    "\"\"\"\n",
    "\n",
    "import csv \n",
    "import time\n",
    "import os.path\n",
    "import datetime as dt\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = None\n",
    "url = None\n",
    "soup = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    print(\"Getting website data\")\n",
    "    global browser, url, soup\n",
    "    \n",
    "    # pilih browser yang akan digunakan. disini saya menggunakan Firefox sebagai client browsernya\n",
    "    browser = webdriver.Firefox()\n",
    "\n",
    "    # masukan URL tujuan\n",
    "    url = 'https://covid19.klungkungkab.go.id/'\n",
    "\n",
    "    # buat request ke URL tujuan\n",
    "    browser.get(url)\n",
    "\n",
    "    # setelah browser selesai membukan URL, mulai parsing file htmlnya\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "buat variabel nama file tujuan menyompan dataset\n",
    "buat initial timestamp / waktu saat script dijalankan\n",
    "\"\"\"\n",
    "\n",
    "csv_file = \"datasets_covid_klk.csv\"\n",
    "csv_row = {\n",
    "    \"timestamp\": dt.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_banjarangkan_data(soup):\n",
    "    print(\"Parsing Data Kecamatan Banjarangkan\")\n",
    "    \n",
    "    # deklarasi kalau kita akan menggunakan variabel global\n",
    "    global csv_row\n",
    "    \n",
    "    # buat dictionary kosong yang nantinya menampung data\n",
    "    dict_banjarangkan_data = {}\n",
    "\n",
    "    # mulai pencarian elemen yang mengandung data\n",
    "    banjarangkan_table = soup.find_all(id=\"piechartKECAMATANBANJARANGKAN\")\n",
    "    banjarangkan_data = (banjarangkan_table[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents)\n",
    "\n",
    "    # memasukan hasil data yang diperoleh ke dictionary\n",
    "    for data in banjarangkan_data:\n",
    "        result = str(data.contents[0].contents[0]).split()\n",
    "        dict_banjarangkan_data[result[0]] = result[1]\n",
    "\n",
    "    # berdasarkan dictionary sebelumnya, kita masukan data-datanya ke dictionary CSV\n",
    "    for x in dict_banjarangkan_data:\n",
    "        if x == \"ODP\":\n",
    "            csv_row[\"banjarangkan_odp\"] = dict_banjarangkan_data[x]\n",
    "\n",
    "        if x == \"OTG\":\n",
    "            csv_row[\"banjarangkan_otg\"] = dict_banjarangkan_data[x]\n",
    "\n",
    "        if x == \"PDP\":\n",
    "            csv_row[\"banjarangkan_pdp\"] = dict_banjarangkan_data[x]\n",
    "\n",
    "        if x == \"Positif\":\n",
    "            csv_row[\"banjarangkan_positif\"] = dict_banjarangkan_data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dawan_data(soup):\n",
    "    print(\"Parsing Data Kecamatan Dawan\")\n",
    "    \n",
    "    # deklarasi kalau kita akan menggunakan variabel global\n",
    "    global csv_row\n",
    "    \n",
    "    dict_dawan_data = {}\n",
    "\n",
    "    dawan_table = soup.find_all(id=\"piechartKECAMATANDAWAN\")\n",
    "    dawan_data = (dawan_table[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents)\n",
    "\n",
    "    for data in dawan_data:\n",
    "        result = str(data.contents[0].contents[0]).split()\n",
    "        dict_dawan_data[result[0]] = result[1]\n",
    "\n",
    "    for x in dict_dawan_data:\n",
    "        if x == \"ODP\":\n",
    "            csv_row[\"dawan_odp\"] = dict_dawan_data[x]\n",
    "\n",
    "        if x == \"OTG\":\n",
    "            csv_row[\"dawan_otg\"] = dict_dawan_data[x]\n",
    "\n",
    "        if x == \"PDP\":\n",
    "            csv_row[\"dawan_pdp\"] = dict_dawan_data[x]\n",
    "\n",
    "        if x == \"Positif\":\n",
    "            csv_row[\"dawan_positif\"] = dict_dawan_data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_klungkung_data(soup):\n",
    "    print(\"Parsing Data Kecamatan Klungkung\")\n",
    "    \n",
    "    # deklarasi kalau kita akan menggunakan variabel global\n",
    "    global csv_row\n",
    "    \n",
    "    dict_klungkung_data = {}\n",
    "\n",
    "    klungkung_table = soup.find_all(id=\"piechartKECAMATANKLUNGKUNG\")\n",
    "    klungkung_data = (klungkung_table[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents)\n",
    "\n",
    "    for data in klungkung_data:\n",
    "        result = str(data.contents[0].contents[0]).split()\n",
    "        dict_klungkung_data[result[0]] = result[1]\n",
    "\n",
    "    for x in dict_klungkung_data:\n",
    "        if x == \"ODP\":\n",
    "            csv_row[\"klungkung_odp\"] = dict_klungkung_data[x]\n",
    "\n",
    "        if x == \"OTG\":\n",
    "            csv_row[\"klungkung_otg\"] = dict_klungkung_data[x]\n",
    "\n",
    "        if x == \"PDP\":\n",
    "            csv_row[\"klungkung_pdp\"] = dict_klungkung_data[x]\n",
    "\n",
    "        if x == \"Positif\":\n",
    "            csv_row[\"klungkung_positif\"] = dict_klungkung_data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nusapenida_data(soup):\n",
    "    print(\"Parsing Data Kecamatan Nusa Penida\")\n",
    "    \n",
    "    # deklarasi kalau kita akan menggunakan variabel global\n",
    "    global csv_row\n",
    "    \n",
    "    dict_nuspen_data = {}\n",
    "\n",
    "    nuspen_table = soup.find_all(id=\"piechartKECAMATANNUSAPENIDA\")\n",
    "    nuspen_data = (nuspen_table[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents[0]\n",
    "     .contents[1]\n",
    "     .contents)\n",
    "\n",
    "    for data in nuspen_data:\n",
    "        result = str(data.contents[0].contents[0]).split()\n",
    "        dict_nuspen_data[result[0]] = result[1]\n",
    "\n",
    "    for x in dict_nuspen_data:\n",
    "        if x == \"ODP\":\n",
    "            csv_row[\"nusapenida_odp\"] = dict_nuspen_data[x]\n",
    "\n",
    "        if x == \"OTG\":\n",
    "            csv_row[\"nusapenida_otg\"] = dict_nuspen_data[x]\n",
    "\n",
    "        if x == \"PDP\":\n",
    "            csv_row[\"nusapenida_pdp\"] = dict_nuspen_data[x]\n",
    "\n",
    "        if x == \"Positif\":\n",
    "            csv_row[\"nusapenida_positif\"] = dict_nuspen_data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wna_data(soup):\n",
    "    print(\"Parsing Data WNA\")\n",
    "    \n",
    "    # deklarasi kalau kita akan menggunakan variabel global\n",
    "    global csv_row\n",
    "    \n",
    "    dict_wna_data = {}\n",
    "\n",
    "    wna_data = soup.find_all(\"h2\")[5].next_sibling.next_sibling\n",
    "    wna_table = wna_data.tr.next_sibling.next_sibling.contents\n",
    "\n",
    "    # karena kebetulan hasil data ini belum 'bersih', jadi dilakukan pembersihan list data\n",
    "    for i in wna_table:\n",
    "        if i == '\\n':\n",
    "            wna_table.remove(i)\n",
    "\n",
    "    dict_wna_data['ODP'] = wna_table[0].contents[0]\n",
    "    dict_wna_data['OTG'] = wna_table[1].contents[0]\n",
    "    dict_wna_data['PDP'] = wna_table[2].contents[0]\n",
    "    dict_wna_data['Positif'] = wna_table[3].contents[0]\n",
    "\n",
    "    for x in dict_wna_data:\n",
    "        if x == \"ODP\":\n",
    "            csv_row[\"wna_odp\"] = dict_wna_data[x]\n",
    "\n",
    "        if x == \"OTG\":\n",
    "            csv_row[\"wna_otg\"] = dict_wna_data[x]\n",
    "\n",
    "        if x == \"PDP\":\n",
    "            csv_row[\"wna_pdp\"] = dict_wna_data[x]\n",
    "\n",
    "        if x == \"Positif\":\n",
    "            csv_row[\"wna_positif\"] = dict_wna_data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_data(soup):\n",
    "    print(\"Parsing Data Total Kabupaten Klungkung\")\n",
    "    \n",
    "    # deklarasi kalau kita akan menggunakan variabel global\n",
    "    global csv_row\n",
    "    \n",
    "    dict_overall_data = {}\n",
    "\n",
    "    overall_data = soup.find_all('div', class_=\"total-div\")\n",
    "\n",
    "    for data in overall_data:\n",
    "        if str(data\n",
    "                .contents[1]\n",
    "                .contents[0]\n",
    "               ) == \"POSITIF\":\n",
    "\n",
    "            dict_overall_data[\"Positif\"] = str(data\n",
    "                    .contents[0]\n",
    "                    .contents[0]\n",
    "                   )\n",
    "        else:\n",
    "            dict_overall_data[\n",
    "                str(data\n",
    "                    .contents[1]\n",
    "                    .contents[0]\n",
    "                   )\n",
    "            ] = str(data\n",
    "                    .contents[0]\n",
    "                    .contents[0]\n",
    "                   )\n",
    "\n",
    "    for x in dict_overall_data:\n",
    "        if x == \"ODP\":\n",
    "            csv_row[\"total_odp\"] = dict_overall_data[x]\n",
    "\n",
    "        if x == \"OTG\":\n",
    "            csv_row[\"total_otg\"] = dict_overall_data[x]\n",
    "\n",
    "        if x == \"PDP\":\n",
    "            csv_row[\"total_pdp\"] = dict_overall_data[x]\n",
    "\n",
    "        if x == \"Positif\":\n",
    "            csv_row[\"total_positif\"] = dict_overall_data[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat header CSV dengan format list\n",
    "csv_head = [\"timestamp\", \n",
    "            \"banjarangkan_odp\", \"banjarangkan_otg\", \"banjarangkan_pdp\", \"banjarangkan_positif\", \n",
    "            \"dawan_odp\", \"dawan_otg\", \"dawan_pdp\", \"dawan_positif\", \n",
    "            \"klungkung_odp\", \"klungkung_otg\", \"klungkung_pdp\", \"klungkung_positif\", \n",
    "            \"nusapenida_odp\", \"nusapenida_otg\", \"nusapenida_pdp\", \"nusapenida_positif\", \n",
    "            \"wna_odp\", \"wna_otg\", \"wna_pdp\", \"wna_positif\", \n",
    "            \"total_odp\", \"total_otg\", \"total_pdp\", \"total_positif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi membuat file CSV baru dengan header pada baris paling atas\n",
    "def create_csv(csv_file, csv_head, csv_row):\n",
    "    print(\"Creating CSV files...\")\n",
    "    \n",
    "    try:\n",
    "        with open(csv_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_head)\n",
    "            writer.writeheader()\n",
    "            writer.writerow(csv_row)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi menambahkan baris ke file CSV baru\n",
    "def insert_csv(csv_file, csv_row):\n",
    "    print(\"Writing to CSV files...\")\n",
    "    \n",
    "    try:\n",
    "        with open(csv_file, 'a+', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_head)\n",
    "            writer.writerow(csv_row)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = True\n",
    "failed_count = 0\n",
    "\n",
    "def run():\n",
    "    global failed, failed_count\n",
    "    \n",
    "    try:\n",
    "        init_browser()\n",
    "        get_banjarangkan_data(soup)\n",
    "        get_dawan_data(soup)\n",
    "        get_klungkung_data(soup)\n",
    "        get_nusapenida_data(soup)\n",
    "        get_wna_data(soup)\n",
    "        get_total_data(soup)\n",
    "        failed = False\n",
    "    except:\n",
    "        print(\"Error index. Retrying in 10 seconds.....\")\n",
    "        failed_count += 1\n",
    "        browser.close()\n",
    "        \n",
    "        if (failed_count > 5):\n",
    "            print(\"5 Times Failed. Skipping this job. Next job in 8 Hours.\")\n",
    "            failed = False\n",
    "        else:\n",
    "            failed = True\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting website data\n",
      "Parsing Data Kecamatan Banjarangkan\n",
      "Parsing Data Kecamatan Dawan\n",
      "Parsing Data Kecamatan Klungkung\n",
      "Parsing Data Kecamatan Nusa Penida\n",
      "Parsing Data WNA\n",
      "Parsing Data Total Kabupaten Klungkung\n"
     ]
    }
   ],
   "source": [
    "while failed:\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CSV files...\n"
     ]
    }
   ],
   "source": [
    "# pengecekan file CSV yang sudah ada. jadi kalau belum ada dia akan membuat yang baru.\n",
    "if os.path.isfile(csv_file):\n",
    "    insert_csv(csv_file, csv_row)\n",
    "else:\n",
    "    create_csv(csv_file, csv_head, csv_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job finished succesfully. Re-run job in 8 hours. Hopefully pandemic will be eradicated soon.\n"
     ]
    }
   ],
   "source": [
    "# setelah selesai parsing, tutup browser untuk memperkecil penggunaan memory (mungkin)\n",
    "browser.close()\n",
    "\n",
    "print(\"Job finished succesfully. Re-run job in 8 hours. Hopefully pandemic will be eradicated soon.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
